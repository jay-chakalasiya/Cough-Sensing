{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T04:17:34.527692Z",
     "start_time": "2021-01-23T04:17:27.870372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['audio_test',\n",
       " 'audio_train',\n",
       " 'sample_submission.csv',\n",
       " 'test_post_competition.csv',\n",
       " 'train.csv',\n",
       " 'train_post_competition.csv']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm.notebook as tqdm\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "os.listdir('data/freesound-audio-tagging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T04:17:34.648103Z",
     "start_time": "2021-01-23T04:17:34.564133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "      <th>manually_verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00044347.wav</td>\n",
       "      <td>Hi-hat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>001ca53d.wav</td>\n",
       "      <td>Saxophone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>002d256b.wav</td>\n",
       "      <td>Trumpet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0033e230.wav</td>\n",
       "      <td>Glockenspiel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>00353774.wav</td>\n",
       "      <td>Cello</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname         label  manually_verified\n",
       "0  00044347.wav        Hi-hat                  0\n",
       "1  001ca53d.wav     Saxophone                  1\n",
       "2  002d256b.wav       Trumpet                  0\n",
       "3  0033e230.wav  Glockenspiel                  1\n",
       "4  00353774.wav         Cello                  1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('data/freesound-audio-tagging/audio_train'))\n",
    "df = pd.read_csv('data/freesound-audio-tagging/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T04:17:48.967341Z",
     "start_time": "2021-01-23T04:17:48.944348Z"
    }
   },
   "outputs": [],
   "source": [
    "sr = 44100\n",
    "input_length = int(sr)\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "def audio_norm(data):\n",
    "    max_data = np.max(data)\n",
    "    min_data = np.min(data)\n",
    "    data = (data-min_data)/(max_data-min_data+1e-6)\n",
    "    return data-0.5\n",
    "\n",
    "\n",
    "def load_audio_file(file_path, input_length=input_length):\n",
    "    data = librosa.core.load(file_path, sr=sr)[0] \n",
    "    \n",
    "    if len(data)>input_length:\n",
    "        max_offset = len(data)-input_length\n",
    "        offset = np.random.randint(max_offset)\n",
    "        data = data[offset:input_length+offset]\n",
    "        \n",
    "    else:\n",
    "        T = np.zeros(input_length, dtype=float)\n",
    "        T[:len(data)] = data\n",
    "        data = T\n",
    "        #max_offset = input_length - len(data)\n",
    "        ##offset = np.random.randint(max_offset)\n",
    "        #data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "        \n",
    "    data = audio_norm(data)\n",
    "    return np.array([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T04:17:54.797951Z",
     "start_time": "2021-01-23T04:17:54.394752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x1296a495f48>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "librosa.display.waveplot(load_audio_file('data/freesound-audio-tagging/audio_train/001ca53d.wav')[0],\n",
    "                         sr=sr, \n",
    "                         max_points=50000.0, \n",
    "                         x_axis='time', \n",
    "                         offset=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T04:17:59.715753Z",
     "start_time": "2021-01-23T04:17:59.705746Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = sorted(set(df.label))\n",
    "label_to_indice = {l:i for i,l in enumerate(labels)}\n",
    "indice_to_label = {i:l for i,l in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T04:18:14.431657Z",
     "start_time": "2021-01-23T04:18:14.382673Z"
    }
   },
   "outputs": [],
   "source": [
    "class FreeSoundDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df_path, data_path, train=True, split=0.8):\n",
    "        \n",
    "        self.df = pd.read_csv(df_path)\n",
    "        \n",
    "        self.df = self.df[:int(len(self.df)*split)] if train else self.df[int(len(self.df)*split):]\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        self.sr = 44100\n",
    "        self.input_length = int(sr)\n",
    "        self.batch_size = 32\n",
    "        \n",
    "        self.labels = sorted(set(self.df.label))\n",
    "        self.label_to_indice = {l:i for i,l in enumerate(self.labels)}\n",
    "        self.indice_to_label = {i:l for i,l in enumerate(self.labels)}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)-2\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.data_path + list(df[idx: idx+1].fname)[0]\n",
    "        label_indice = label_to_indice[list(df[idx: idx+1].label)[0]]\n",
    "        return load_audio_file(file_path), label_indice\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T04:18:15.833617Z",
     "start_time": "2021-01-23T04:18:15.817622Z"
    }
   },
   "outputs": [],
   "source": [
    "def bandpass_filter(signal, low, high, order = 5):\n",
    "    sos = butter(order, [low, high], analog = False, btype = 'band', output = 'sos')\n",
    "    y = sosfilt(sos, signal)\n",
    "    return y\n",
    "    \n",
    "def make_signal(raw_signal, nyq = sr/2):\n",
    "    return_signal = np.zeros((8, self.input_length))\n",
    "    return_signal[0] = raw_signal\n",
    "\n",
    "    cut_offs = [i/nyq for i in [1, 256, 512, 1024, 2048, 4096, 8192, 11024]]\n",
    "    for i in range(1, len(cut_offs), 1):\n",
    "        return_signal[i] = bandpass_filter(raw_signal, cut_offs[i-1], cut_offs[i])\n",
    "    return return_signal\n",
    "        \n",
    "    \n",
    "def shuffletwo(x, y):\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(x)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T04:18:20.201488Z",
     "start_time": "2021-01-23T04:18:20.138508Z"
    }
   },
   "outputs": [],
   "source": [
    "FreeSoundData = FreeSoundDataset('data/freesound-audio-tagging/train.csv',\n",
    "                                 'data/freesound-audio-tagging/audio_train/')\n",
    "FreeSoundDataTest = FreeSoundDataset('data/freesound-audio-tagging/train.csv',\n",
    "                                     'data/freesound-audio-tagging/audio_train/',\n",
    "                                     train=False)\n",
    "FreeSoundDataLoader = DataLoader(FreeSoundData, batch_size=64, shuffle=True)\n",
    "FreeSoundDataTestLoader = DataLoader(FreeSoundDataTest, batch_size=64, shuffle=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T04:18:27.171752Z",
     "start_time": "2021-01-23T04:18:27.115761Z"
    }
   },
   "outputs": [],
   "source": [
    "class FreeSound_Sense(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(FreeSound_Sense, self).__init__()\n",
    "        self.conv1d_1_16_9 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=9, padding=True)\n",
    "        self.conv1d_16_16_9 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=9, padding=True)\n",
    "        self.conv1d_16_32_3 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=True)\n",
    "        self.conv1d_32_32_3 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=True)\n",
    "        self.conv1d_32_256_3 = nn.Conv1d(in_channels=32, out_channels=256, kernel_size=3, padding=True)\n",
    "        self.conv1d_256_256_3 = nn.Conv1d(in_channels=256, out_channels=256, kernel_size=3, padding=True)\n",
    "        \n",
    "        self.maxpool_16 = nn.MaxPool1d(16)\n",
    "        self.maxpool_4 = nn.MaxPool1d(4)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigm = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        self.fc_256_64 = nn.Linear(in_features=256, out_features=64)\n",
    "        self.fc_64_1024 = nn.Linear(in_features=64, out_features=1024)\n",
    "        self.fc_1024_42 = nn.Linear(in_features=1024, out_features=42)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # First Block\n",
    "        x = self.conv1d_1_16_9(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv1d_16_16_9(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool_16(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Second Block\n",
    "        x = self.conv1d_16_32_3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv1d_32_32_3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool_4(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Third Block\n",
    "        x = self.conv1d_32_32_3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv1d_32_32_3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool_4(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Fourth Block\n",
    "        x = self.conv1d_32_256_3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv1d_256_256_3(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.mean(x, 2)\n",
    " \n",
    "        # Final Layers\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc_256_64(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc_64_1024(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc_1024_42(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T04:18:45.609731Z",
     "start_time": "2021-01-23T04:18:38.842426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1            [-1, 16, 44094]             160\n",
      "              ReLU-2            [-1, 16, 44094]               0\n",
      "            Conv1d-3            [-1, 16, 44088]           2,320\n",
      "              ReLU-4            [-1, 16, 44088]               0\n",
      "         MaxPool1d-5             [-1, 16, 2755]               0\n",
      "           Dropout-6             [-1, 16, 2755]               0\n",
      "            Conv1d-7             [-1, 32, 2755]           1,568\n",
      "              ReLU-8             [-1, 32, 2755]               0\n",
      "            Conv1d-9             [-1, 32, 2755]           3,104\n",
      "             ReLU-10             [-1, 32, 2755]               0\n",
      "        MaxPool1d-11              [-1, 32, 688]               0\n",
      "          Dropout-12              [-1, 32, 688]               0\n",
      "           Conv1d-13              [-1, 32, 688]           3,104\n",
      "             ReLU-14              [-1, 32, 688]               0\n",
      "           Conv1d-15              [-1, 32, 688]           3,104\n",
      "             ReLU-16              [-1, 32, 688]               0\n",
      "        MaxPool1d-17              [-1, 32, 172]               0\n",
      "          Dropout-18              [-1, 32, 172]               0\n",
      "           Conv1d-19             [-1, 256, 172]          24,832\n",
      "             ReLU-20             [-1, 256, 172]               0\n",
      "           Conv1d-21             [-1, 256, 172]         196,864\n",
      "             ReLU-22             [-1, 256, 172]               0\n",
      "           Linear-23                   [-1, 64]          16,448\n",
      "             ReLU-24                   [-1, 64]               0\n",
      "           Linear-25                 [-1, 1024]          66,560\n",
      "             ReLU-26                 [-1, 1024]               0\n",
      "           Linear-27                   [-1, 42]          43,050\n",
      "          Softmax-28                   [-1, 42]               0\n",
      "================================================================\n",
      "Total params: 361,114\n",
      "Trainable params: 361,114\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.17\n",
      "Forward/backward pass size (MB): 27.34\n",
      "Params size (MB): 1.38\n",
      "Estimated Total Size (MB): 28.89\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "Model = FreeSound_Sense()\n",
    "Model.float()\n",
    "Model.to(device)\n",
    "summary(Model, (1, 44100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T04:19:19.613859Z",
     "start_time": "2021-01-23T04:19:15.415874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreeSound_Sense(\n",
       "  (conv1d_1_16_9): Conv1d(1, 16, kernel_size=(9,), stride=(1,), padding=(True,))\n",
       "  (conv1d_16_16_9): Conv1d(16, 16, kernel_size=(9,), stride=(1,), padding=(True,))\n",
       "  (conv1d_16_32_3): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(True,))\n",
       "  (conv1d_32_32_3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(True,))\n",
       "  (conv1d_32_256_3): Conv1d(32, 256, kernel_size=(3,), stride=(1,), padding=(True,))\n",
       "  (conv1d_256_256_3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(True,))\n",
       "  (maxpool_16): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)\n",
       "  (maxpool_4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu): ReLU()\n",
       "  (sigm): Sigmoid()\n",
       "  (softmax): Softmax(dim=1)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc_256_64): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (fc_64_1024): Linear(in_features=64, out_features=1024, bias=True)\n",
       "  (fc_1024_42): Linear(in_features=1024, out_features=42, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "#Model = FreeSound_Sense()\n",
    "#Model.float()\n",
    "#Model.to(device)\n",
    "\n",
    "Model = FreeSound_Sense()\n",
    "Model.load_state_dict(torch.load(\"FreeSound_1D_conv_global_pool_1013_epoch.stDict\"))\n",
    "Model.float()\n",
    "Model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T04:19:31.240691Z",
     "start_time": "2021-01-23T04:19:31.228696Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(Model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(Model.parameters(), lr=0.0005, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-23T04:19:33.547Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004279b1e52a476897b24b4d397ef242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57607e01b054044bd98e84ac00030b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=119), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_progress_bar = tqdm.tqdm(range(0, 50))\n",
    "for epoch in epoch_progress_bar:\n",
    "    avg_epoch_loss = 0\n",
    "    data_progress_bar = tqdm.tqdm(FreeSoundDataLoader)\n",
    "    positives=0\n",
    "    for data, targets in data_progress_bar:\n",
    "        data = data.float().to(device)\n",
    "        targets = targets.long().to(device)\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = Model(data)\n",
    "        \n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_val = loss.item()\n",
    "        avg_epoch_loss+=loss_val\n",
    "        data_progress_bar.set_description(desc=\"Loss: \"+str(loss_val))\n",
    "        \n",
    "        outputs = np.argmax(outputs.detach().cpu().numpy(), axis=1)\n",
    "        targets = targets.cpu().numpy()\n",
    "        positives += np.sum(targets==outputs)\n",
    "    \n",
    "    print('Epoch Loss: ', str(avg_epoch_loss/len(FreeSoundDataLoader)))\n",
    "    print('Train Acc ', str(positives*100/(len(FreeSoundDataLoader)*64)))\n",
    "    \n",
    "    # Validation\n",
    "    data_test_progress_bar = tqdm.tqdm(FreeSoundDataTestLoader)\n",
    "    positives=0\n",
    "    for data, targets in data_test_progress_bar:\n",
    "        data = data.float().to(device)\n",
    "        targets = targets.numpy()\n",
    "        outputs = Model(data)\n",
    "        outputs = np.argmax(outputs.detach().cpu().numpy(), axis=1)\n",
    "        positives += np.sum(targets==outputs)\n",
    "        \n",
    "    print('Valid Acc ', str(positives*100/(len(FreeSoundDataTestLoader)*64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T02:11:31.634924Z",
     "start_time": "2021-01-23T02:11:31.592937Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(Model.state_dict(), \"FreeSound_44100_1D_conv_global_pool_1313_epoch.stDict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T02:11:51.606994Z",
     "start_time": "2021-01-23T02:11:50.936033Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.375 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(tensor(11), False),\n",
       " (tensor(1), False),\n",
       " (tensor(32), True),\n",
       " (tensor(39), True),\n",
       " (tensor(23), False),\n",
       " (tensor(26), True),\n",
       " (tensor(14), False),\n",
       " (tensor(37), False),\n",
       " (tensor(34), False),\n",
       " (tensor(6), False),\n",
       " (tensor(22), False),\n",
       " (tensor(36), True),\n",
       " (tensor(1), False),\n",
       " (tensor(38), False),\n",
       " (tensor(0), True),\n",
       " (tensor(35), False),\n",
       " (tensor(17), False),\n",
       " (tensor(10), False),\n",
       " (tensor(21), False),\n",
       " (tensor(12), True),\n",
       " (tensor(23), True),\n",
       " (tensor(1), False),\n",
       " (tensor(6), True),\n",
       " (tensor(5), False),\n",
       " (tensor(21), False),\n",
       " (tensor(1), False),\n",
       " (tensor(35), True),\n",
       " (tensor(34), False),\n",
       " (tensor(32), True),\n",
       " (tensor(28), False),\n",
       " (tensor(12), True),\n",
       " (tensor(12), True)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "for data in FreeSoundDataLoader:\n",
    "    if i==2:\n",
    "        O = Model(data[0].float().to(device))\n",
    "        A = data[1]\n",
    "        #print(data[1])\n",
    "        break\n",
    "    i+=1\n",
    "O = O.detach().cpu().numpy()\n",
    "K = np.argmax(O, axis=1)==A.numpy()\n",
    "print(np.sum(K)/len(K), np.sum(K))\n",
    "list(zip(A, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
