{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T18:52:22.910430Z",
     "start_time": "2021-02-08T18:52:22.904431Z"
    }
   },
   "source": [
    "# saved models are named as FreeSound_1D_conv_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T05:07:06.843103Z",
     "start_time": "2021-02-09T05:07:02.144610Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['audio_test',\n",
       " 'audio_train',\n",
       " 'free_sound_11025.pkl',\n",
       " 'free_sound_22050.pkl',\n",
       " 'sample_submission.csv',\n",
       " 'test_post_competition.csv',\n",
       " 'train.csv',\n",
       " 'train_post_competition.csv']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm.notebook as tqdm\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "os.listdir('data/freesound-audio-tagging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T05:07:06.916079Z",
     "start_time": "2021-02-09T05:07:06.858098Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "      <th>manually_verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00044347.wav</td>\n",
       "      <td>Hi-hat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>001ca53d.wav</td>\n",
       "      <td>Saxophone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>002d256b.wav</td>\n",
       "      <td>Trumpet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0033e230.wav</td>\n",
       "      <td>Glockenspiel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>00353774.wav</td>\n",
       "      <td>Cello</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname         label  manually_verified\n",
       "0  00044347.wav        Hi-hat                  0\n",
       "1  001ca53d.wav     Saxophone                  1\n",
       "2  002d256b.wav       Trumpet                  0\n",
       "3  0033e230.wav  Glockenspiel                  1\n",
       "4  00353774.wav         Cello                  1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('data/freesound-audio-tagging/audio_train'))\n",
    "df = pd.read_csv('data/freesound-audio-tagging/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T05:07:27.805384Z",
     "start_time": "2021-02-09T05:07:24.100572Z"
    }
   },
   "outputs": [],
   "source": [
    "Loaded_data = {}\n",
    "if os.path.exists('data/freesound-audio-tagging/free_sound_11025.pkl'):\n",
    "    Loaded_data = pickle.load(open('data/freesound-audio-tagging/free_sound_11025.pkl', 'rb'))\n",
    "    \n",
    "def audio_norm(data):\n",
    "    max_data = np.max(data)\n",
    "    min_data = np.min(data)\n",
    "    data = (data-min_data)/(max_data-min_data+1e-6)\n",
    "    return data-0.5\n",
    "\n",
    "def load_audio_file(file_path, input_length=4096):\n",
    "    \n",
    "    if file_path not in Loaded_data:\n",
    "        data = librosa.core.load(file_path, sr=None) \n",
    "        data = librosa.core.resample(data[0], data[1], 11025)\n",
    "        Loaded_data[file_path] = data\n",
    "    else:\n",
    "        data = Loaded_data[file_path]\n",
    "    \n",
    "    if len(data)>input_length:\n",
    "        max_offset = len(data)-input_length\n",
    "        offset = np.random.randint(max_offset)\n",
    "        data = data[offset:input_length+offset]\n",
    "        \n",
    "    else:\n",
    "        T = np.zeros(input_length, dtype=float)\n",
    "        T[:len(data)] = data\n",
    "        data = T\n",
    "        #max_offset = input_length - len(data)\n",
    "        ##offset = np.random.randint(max_offset)\n",
    "        #data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "        \n",
    "    data = audio_norm(data)\n",
    "    return np.array([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T05:07:31.026352Z",
     "start_time": "2021-02-09T05:07:30.845412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x257f0e8ad88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "librosa.display.waveplot(load_audio_file('data/freesound-audio-tagging/audio_train/001ca53d.wav')[0],\n",
    "                         sr=11025, \n",
    "                         max_points=50000.0, \n",
    "                         x_axis='time', \n",
    "                         offset=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T05:07:33.067698Z",
     "start_time": "2021-02-09T05:07:33.058701Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = sorted(set(df.label))\n",
    "label_to_indice = {l:i for i,l in enumerate(labels)}\n",
    "indice_to_label = {i:l for i,l in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T05:07:35.398950Z",
     "start_time": "2021-02-09T05:07:35.385955Z"
    }
   },
   "outputs": [],
   "source": [
    "class FreeSoundDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df_path, data_path, train=True, split=0.8):\n",
    "        \n",
    "        self.df = pd.read_csv(df_path)\n",
    "        \n",
    "        self.df = self.df[:int(len(self.df)*split)] if train else self.df[int(len(self.df)*split):]\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        self.input_length = 4096\n",
    "        self.batch_size = 32\n",
    "        \n",
    "        self.labels = sorted(set(self.df.label))\n",
    "        self.label_to_indice = {l:i for i,l in enumerate(self.labels)}\n",
    "        self.indice_to_label = {i:l for i,l in enumerate(self.labels)}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)-2\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.data_path + list(df[idx: idx+1].fname)[0]\n",
    "        label_indice = label_to_indice[list(df[idx: idx+1].label)[0]]\n",
    "        return load_audio_file(file_path), label_indice\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T05:07:38.158067Z",
     "start_time": "2021-02-09T05:07:38.142073Z"
    }
   },
   "outputs": [],
   "source": [
    "sr = 11025\n",
    "def bandpass_filter(signal, low, high, order = 5):\n",
    "    sos = butter(order, [low, high], analog = False, btype = 'band', output = 'sos')\n",
    "    y = sosfilt(sos, signal)\n",
    "    return y\n",
    "    \n",
    "def make_signal(raw_signal, nyq = sr/2):\n",
    "    return_signal = np.zeros((8, self.input_length))\n",
    "    return_signal[0] = raw_signal\n",
    "\n",
    "    cut_offs = [i/nyq for i in [1, 256, 512, 1024, 2048, 4096, 8192, 11024]]\n",
    "    for i in range(1, len(cut_offs), 1):\n",
    "        return_signal[i] = bandpass_filter(raw_signal, cut_offs[i-1], cut_offs[i])\n",
    "    return return_signal\n",
    "        \n",
    "    \n",
    "def shuffletwo(x, y):\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(x)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T05:07:40.620277Z",
     "start_time": "2021-02-09T05:07:40.586288Z"
    }
   },
   "outputs": [],
   "source": [
    "mini_batch_size = 96\n",
    "FreeSoundData = FreeSoundDataset('data/freesound-audio-tagging/train.csv',\n",
    "                                 'data/freesound-audio-tagging/audio_train/')\n",
    "FreeSoundDataTest = FreeSoundDataset('data/freesound-audio-tagging/train.csv',\n",
    "                                     'data/freesound-audio-tagging/audio_train/',\n",
    "                                     train=False)\n",
    "FreeSoundDataLoader = DataLoader(FreeSoundData, batch_size=mini_batch_size, shuffle=True)\n",
    "FreeSoundDataTestLoader = DataLoader(FreeSoundDataTest, batch_size=mini_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T05:07:44.588006Z",
     "start_time": "2021-02-09T05:07:44.579008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4096)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FreeSoundData[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T05:13:27.306185Z",
     "start_time": "2021-02-09T05:13:26.972293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 16, 4090]             160\n",
      "              ReLU-2             [-1, 16, 4090]               0\n",
      "            Conv1d-3             [-1, 16, 4084]           2,320\n",
      "              ReLU-4             [-1, 16, 4084]               0\n",
      "         MaxPool1d-5              [-1, 16, 255]               0\n",
      "           Dropout-6              [-1, 16, 255]               0\n",
      "            Conv1d-7              [-1, 32, 255]           1,568\n",
      "              ReLU-8              [-1, 32, 255]               0\n",
      "            Conv1d-9              [-1, 32, 255]           3,104\n",
      "             ReLU-10              [-1, 32, 255]               0\n",
      "        MaxPool1d-11               [-1, 32, 63]               0\n",
      "          Dropout-12               [-1, 32, 63]               0\n",
      "           Conv1d-13               [-1, 32, 63]           3,104\n",
      "             ReLU-14               [-1, 32, 63]               0\n",
      "           Conv1d-15               [-1, 32, 63]           3,104\n",
      "             ReLU-16               [-1, 32, 63]               0\n",
      "        MaxPool1d-17               [-1, 32, 15]               0\n",
      "          Dropout-18               [-1, 32, 15]               0\n",
      "           Conv1d-19               [-1, 64, 15]           6,208\n",
      "             ReLU-20               [-1, 64, 15]               0\n",
      "           Conv1d-21               [-1, 64, 15]          12,352\n",
      "             ReLU-22               [-1, 64, 15]               0\n",
      "        MaxPool1d-23                [-1, 64, 3]               0\n",
      "           Linear-24                   [-1, 64]           4,160\n",
      "             ReLU-25                   [-1, 64]               0\n",
      "           Linear-26                  [-1, 512]          33,280\n",
      "             ReLU-27                  [-1, 512]               0\n",
      "           Linear-28                   [-1, 42]          21,546\n",
      "          Softmax-29                   [-1, 42]               0\n",
      "================================================================\n",
      "Total params: 90,906\n",
      "Trainable params: 90,906\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 2.45\n",
      "Params size (MB): 0.35\n",
      "Estimated Total Size (MB): 2.81\n",
      "----------------------------------------------------------------\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[WARN] Cannot find rule for <class 'torch.nn.modules.activation.Sigmoid'>. Treat it as zero Macs and zero Params.\n",
      "[WARN] Cannot find rule for <class 'torch.nn.modules.activation.Softmax'>. Treat it as zero Macs and zero Params.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[WARN] Cannot find rule for <class '__main__.FreeSound_Sense'>. Treat it as zero Macs and zero Params.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12048512.0, 84698.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FreeSound_Sense(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(FreeSound_Sense, self).__init__()\n",
    "        self.conv1d_1_16_9 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=9, padding=True)\n",
    "        self.conv1d_16_16_9 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=9, padding=True)\n",
    "        self.conv1d_16_32_3 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=True)\n",
    "        self.conv1d_32_32_3 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=True)\n",
    "        self.conv1d_32_64_3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=True)\n",
    "        self.conv1d_64_64_3 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=True)\n",
    "        \n",
    "        self.maxpool_16 = nn.MaxPool1d(16)\n",
    "        self.maxpool_4 = nn.MaxPool1d(4)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigm = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        self.fc_64_64 = nn.Linear(in_features=64, out_features=64)\n",
    "        self.fc_64_512 = nn.Linear(in_features=64, out_features=512)\n",
    "        self.fc_512_42 = nn.Linear(in_features=512, out_features=42)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # First Block\n",
    "        x = self.conv1d_1_16_9(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv1d_16_16_9(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool_16(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Second Block\n",
    "        x = self.conv1d_16_32_3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv1d_32_32_3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool_4(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Third Block\n",
    "        x = self.conv1d_32_32_3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv1d_32_32_3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool_4(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Fourth Block\n",
    "        x = self.conv1d_32_64_3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv1d_64_64_3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool_4(x)\n",
    "        x = torch.mean(x, 2)\n",
    " \n",
    "        # Final Layers\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc_64_64(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc_64_512(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc_512_42(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "Model = FreeSound_Sense()\n",
    "Model.float()\n",
    "Model.to(device)\n",
    "summary(Model, (1, 4096))\n",
    "\n",
    "from thop import profile\n",
    "macs, params = profile(Model, inputs=(torch.randn(1, 1, 4096).to(device), ))\n",
    "macs, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T05:13:33.935061Z",
     "start_time": "2021-02-09T05:13:33.927063Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(Model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(Model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-09T05:13:39.135Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8abc3cc64e4b01bef8ae6ae3984df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39420597e54c42e9b22d7020ce6e91f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=79), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_progress_bar = tqdm.tqdm(range(0, 500))\n",
    "for epoch in epoch_progress_bar:\n",
    "    avg_epoch_loss = 0\n",
    "    data_progress_bar = tqdm.tqdm(FreeSoundDataLoader)\n",
    "    positives=0\n",
    "    for data, targets in data_progress_bar:\n",
    "        data = data.float().to(device)\n",
    "        targets = targets.long().to(device)\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = Model(data)\n",
    "        \n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_val = loss.item()\n",
    "        avg_epoch_loss+=loss_val\n",
    "        data_progress_bar.set_description(desc=\"Loss: \"+str(loss_val))\n",
    "        \n",
    "        outputs = np.argmax(outputs.detach().cpu().numpy(), axis=1)\n",
    "        targets = targets.cpu().numpy()\n",
    "        positives += np.sum(targets==outputs)\n",
    "    \n",
    "    print('Epoch Loss: ', str(avg_epoch_loss/len(FreeSoundDataLoader)))\n",
    "    print('Train Acc ', str(positives*100/(len(FreeSoundDataLoader)*mini_batch_size)))\n",
    "    \n",
    "    # Validation\n",
    "    data_test_progress_bar = tqdm.tqdm(FreeSoundDataTestLoader)\n",
    "    positives=0\n",
    "    for data, targets in data_test_progress_bar:\n",
    "        data = data.float().to(device)\n",
    "        targets = targets.numpy()\n",
    "        outputs = Model(data)\n",
    "        outputs = np.argmax(outputs.detach().cpu().numpy(), axis=1)\n",
    "        positives += np.sum(targets==outputs)\n",
    "        \n",
    "    print('Valid Acc ', str(positives*100/(len(FreeSoundDataTestLoader)*mini_batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T04:51:50.233828Z",
     "start_time": "2021-02-09T04:51:50.193840Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(Model.state_dict(), \"model_weights/FreeSound_1D_conv_smaller_400_epoch.stDict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T06:38:17.405822Z",
     "start_time": "2021-01-22T06:38:16.336518Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3125 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(tensor(0), False),\n",
       " (tensor(3), True),\n",
       " (tensor(12), False),\n",
       " (tensor(25), False),\n",
       " (tensor(15), True),\n",
       " (tensor(20), False),\n",
       " (tensor(4), False),\n",
       " (tensor(12), False),\n",
       " (tensor(34), False),\n",
       " (tensor(13), False),\n",
       " (tensor(24), False),\n",
       " (tensor(26), True),\n",
       " (tensor(7), False),\n",
       " (tensor(22), False),\n",
       " (tensor(40), True),\n",
       " (tensor(20), True),\n",
       " (tensor(17), True),\n",
       " (tensor(32), True),\n",
       " (tensor(7), False),\n",
       " (tensor(24), False),\n",
       " (tensor(29), False),\n",
       " (tensor(10), False),\n",
       " (tensor(38), True),\n",
       " (tensor(34), False),\n",
       " (tensor(30), True),\n",
       " (tensor(17), False),\n",
       " (tensor(26), True),\n",
       " (tensor(18), False),\n",
       " (tensor(12), False),\n",
       " (tensor(17), False),\n",
       " (tensor(1), False),\n",
       " (tensor(39), False)]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "for data in FreeSoundDataLoader:\n",
    "    if i==4:\n",
    "        O = Model(data[0].float().to(device))\n",
    "        A = data[1]\n",
    "        #print(data[1])\n",
    "        break\n",
    "    i+=1\n",
    "O = O.detach().cpu().numpy()\n",
    "K = np.argmax(O, axis=1)==A.numpy()\n",
    "print(np.sum(K)/len(K), np.sum(K))\n",
    "list(zip(A, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
