{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T23:52:35.642450Z",
     "start_time": "2021-02-08T23:52:35.637451Z"
    }
   },
   "source": [
    "## This COugh Model is base on the Freesound-1D CNN GlobalPool file\n",
    "\n",
    "#### here I have transfered the trained weights from that model to retrain on cough or not cough dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T03:38:13.347833Z",
     "start_time": "2021-02-09T03:38:05.707277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Annotations.csv', 'data']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm.notebook as tqdm\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "import random\n",
    "os.listdir('data/collected/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T03:38:13.434805Z",
     "start_time": "2021-02-09T03:38:13.384822Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>user_name</th>\n",
       "      <th>type_dir</th>\n",
       "      <th>directory</th>\n",
       "      <th>filename</th>\n",
       "      <th>times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>sample_¦-¦ú++</td>\n",
       "      <td>quiet</td>\n",
       "      <td>cough</td>\n",
       "      <td>ZOOM0123_LR/Tr1/Tr2/Tr3.WAV</td>\n",
       "      <td>1.6 1.8 3.6 4.0 6.1 6.6 9.1 9.5 11.9 12.3 14.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sample_¦-¦ú++</td>\n",
       "      <td>quiet</td>\n",
       "      <td>continuous_cough</td>\n",
       "      <td>ZOOM0124_LR/Tr1/Tr2/Tr3.WAV</td>\n",
       "      <td>2.2 3.2 5.4 6.5 9.4 10.5 13.0 14.2 16.6 17.7 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>sample_¦-¦ú++</td>\n",
       "      <td>quiet</td>\n",
       "      <td>throat_clear</td>\n",
       "      <td>ZOOM0125_LR/Tr1/Tr2/Tr3.WAV</td>\n",
       "      <td>1.8 2.2 4.2 4.6 7.2 7.6 10.0 10.4 12.9 13.3 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>sample_¦-¦ú++</td>\n",
       "      <td>partitially_noisy</td>\n",
       "      <td>cough</td>\n",
       "      <td>ZOOM0120_LR/Tr1/Tr2/Tr3.WAV</td>\n",
       "      <td>1.2 1.5 3.2 3.5 5.8 6.2 8.3 8.6 10.9 11.2 13.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>sample_¦-¦ú++</td>\n",
       "      <td>partitially_noisy</td>\n",
       "      <td>continuous_cough</td>\n",
       "      <td>ZOOM0121_LR/Tr1/Tr2/Tr3.WAV</td>\n",
       "      <td>1.2 2.1 3.9 4.8 7.3 8.3 10.6 11.6 14.4 15.5 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>176</td>\n",
       "      <td>sample_++¦++e-¦</td>\n",
       "      <td>partitially_noisy</td>\n",
       "      <td>continuous_cough</td>\n",
       "      <td>ZOOM0028_LR/Tr1/Tr2/Tr3.WAV</td>\n",
       "      <td>1.6 2.4 4.6 5.7 9.2 10.5 13.8 14.5 18.1 18.8 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>177</td>\n",
       "      <td>sample_++¦++e-¦</td>\n",
       "      <td>partitially_noisy</td>\n",
       "      <td>throat_clear</td>\n",
       "      <td>ZOOM0029_LR/Tr1/Tr2/Tr3.WAV</td>\n",
       "      <td>1.1 1.7 4.4 4.8 7.6 8.2 16.7 17.2 23.2 23.5 28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>178</td>\n",
       "      <td>sample_++¦++e-¦</td>\n",
       "      <td>noisy</td>\n",
       "      <td>cough</td>\n",
       "      <td>ZOOM0023_LR/Tr1/Tr2/Tr3.WAV</td>\n",
       "      <td>1.5 1.9 6.7 7.2 12.3 12.6 18.4 18.8 23.2 23.6 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>179</td>\n",
       "      <td>sample_++¦++e-¦</td>\n",
       "      <td>noisy</td>\n",
       "      <td>continuous_cough</td>\n",
       "      <td>ZOOM0024_LR/Tr1/Tr2/Tr3.WAV</td>\n",
       "      <td>0.9 2.0 3.9 5.4 8.4 9.0 11.7 12.9 15.9 17.1 24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>sample_++¦++e-¦</td>\n",
       "      <td>noisy</td>\n",
       "      <td>throat_clear</td>\n",
       "      <td>ZOOM0025_LR/Tr1/Tr2/Tr3.WAV</td>\n",
       "      <td>1.2 1.7 4.7 5.3 8.3 9.0 17.8 18.3 25.0 25.5 31...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index        user_name           type_dir         directory  \\\n",
       "0        1    sample_¦-¦ú++              quiet             cough   \n",
       "1        2    sample_¦-¦ú++              quiet  continuous_cough   \n",
       "2        3    sample_¦-¦ú++              quiet      throat_clear   \n",
       "3        4    sample_¦-¦ú++  partitially_noisy             cough   \n",
       "4        5    sample_¦-¦ú++  partitially_noisy  continuous_cough   \n",
       "..     ...              ...                ...               ...   \n",
       "175    176  sample_++¦++e-¦  partitially_noisy  continuous_cough   \n",
       "176    177  sample_++¦++e-¦  partitially_noisy      throat_clear   \n",
       "177    178  sample_++¦++e-¦              noisy             cough   \n",
       "178    179  sample_++¦++e-¦              noisy  continuous_cough   \n",
       "179    180  sample_++¦++e-¦              noisy      throat_clear   \n",
       "\n",
       "                        filename  \\\n",
       "0    ZOOM0123_LR/Tr1/Tr2/Tr3.WAV   \n",
       "1    ZOOM0124_LR/Tr1/Tr2/Tr3.WAV   \n",
       "2    ZOOM0125_LR/Tr1/Tr2/Tr3.WAV   \n",
       "3    ZOOM0120_LR/Tr1/Tr2/Tr3.WAV   \n",
       "4    ZOOM0121_LR/Tr1/Tr2/Tr3.WAV   \n",
       "..                           ...   \n",
       "175  ZOOM0028_LR/Tr1/Tr2/Tr3.WAV   \n",
       "176  ZOOM0029_LR/Tr1/Tr2/Tr3.WAV   \n",
       "177  ZOOM0023_LR/Tr1/Tr2/Tr3.WAV   \n",
       "178  ZOOM0024_LR/Tr1/Tr2/Tr3.WAV   \n",
       "179  ZOOM0025_LR/Tr1/Tr2/Tr3.WAV   \n",
       "\n",
       "                                                 times  \n",
       "0    1.6 1.8 3.6 4.0 6.1 6.6 9.1 9.5 11.9 12.3 14.9...  \n",
       "1    2.2 3.2 5.4 6.5 9.4 10.5 13.0 14.2 16.6 17.7 2...  \n",
       "2    1.8 2.2 4.2 4.6 7.2 7.6 10.0 10.4 12.9 13.3 15...  \n",
       "3    1.2 1.5 3.2 3.5 5.8 6.2 8.3 8.6 10.9 11.2 13.3...  \n",
       "4    1.2 2.1 3.9 4.8 7.3 8.3 10.6 11.6 14.4 15.5 18...  \n",
       "..                                                 ...  \n",
       "175  1.6 2.4 4.6 5.7 9.2 10.5 13.8 14.5 18.1 18.8 2...  \n",
       "176  1.1 1.7 4.4 4.8 7.6 8.2 16.7 17.2 23.2 23.5 28...  \n",
       "177  1.5 1.9 6.7 7.2 12.3 12.6 18.4 18.8 23.2 23.6 ...  \n",
       "178  0.9 2.0 3.9 5.4 8.4 9.0 11.7 12.9 15.9 17.1 24...  \n",
       "179  1.2 1.7 4.7 5.3 8.3 9.0 17.8 18.3 25.0 25.5 31...  \n",
       "\n",
       "[180 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/collected/Annotations.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T22:13:58.179785Z",
     "start_time": "2021-02-08T22:13:58.166789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.8, 4.0, 6.6, 9.5, 12.3, 15.4, 18.7, 21.9, 24.8, 28.0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[float(v) for v in list(df[0:1].times)[0].split(' ')[1::2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T04:25:15.019990Z",
     "start_time": "2021-02-09T03:38:33.706310Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2be84962bb482596d7fcbd2be13bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=180), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_path = 'data/collected/data/'\n",
    "positives = {}\n",
    "negatives = {}\n",
    "\n",
    "for i in tqdm.tqdm(range(len(df))):\n",
    "    \n",
    "    user_name = list(df[i:i+1].user_name)[0]\n",
    "    type_dir = list(df[i:i+1].type_dir)[0]\n",
    "    directory = list(df[i:i+1].directory)[0]\n",
    "    filename = list(df[i:i+1].filename)[0].split('_')[0]+'_'\n",
    "    \n",
    "    start_times = [float(v) for v in list(df[i:i+1].times)[0].strip().split(' ')[::2]]\n",
    "    end_times = [float(v) for v in list(df[i:i+1].times)[0].strip().split(' ')[1::2]]\n",
    "    \n",
    "    dir_path = user_name +'/'+type_dir+'/'+directory+'/'+filename\n",
    "    \n",
    "    post_fixes = ['LR', 'Tr1', 'Tr2', 'Tr3']\n",
    "    for post_fix in post_fixes:\n",
    "        file_path = base_path + dir_path + post_fix + '.wav'\n",
    "        \n",
    "        raw_data = librosa.core.load(file_path, sr=None)\n",
    "        audio_length = len(raw_data[0])/raw_data[1]\n",
    "        \n",
    "        target_sr = 11025\n",
    "        resampled_data = librosa.core.resample(raw_data[0], raw_data[1], target_sr)\n",
    "        \n",
    "        last = 0.0\n",
    "        for j, (st, et) in enumerate(zip(start_times, end_times)):\n",
    "            negatives[dir_path + post_fix + '.wav/'+str(j)] = resampled_data[int(last*target_sr): int(st*target_sr)]\n",
    "            positives[dir_path + post_fix + '.wav/'+str(j)] = resampled_data[int(st*target_sr): int(et*target_sr)]\n",
    "            last = et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T04:26:52.848642Z",
     "start_time": "2021-02-09T04:26:50.183497Z"
    }
   },
   "outputs": [],
   "source": [
    "# save dictionary in pickle file\n",
    "import pickle\n",
    "output = open('data/collected/data/collected_data_11025.pkl', 'wb')\n",
    "pickle.dump(positives, output)\n",
    "output.close()\n",
    "\n",
    "output = open('data/collected/data/collected_data_neg_11025.pkl', 'wb')\n",
    "pickle.dump(negatives, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T04:27:41.699990Z",
     "start_time": "2021-02-09T04:27:39.010851Z"
    }
   },
   "outputs": [],
   "source": [
    "Loaded_data = {}\n",
    "if os.path.exists('data/freesound-audio-tagging/free_sound_11025.pkl'):\n",
    "    Loaded_data = pickle.load(open('data/freesound-audio-tagging/free_sound_11025.pkl', 'rb'))\n",
    "    \n",
    "def audio_norm(data):\n",
    "    max_data = np.max(data)\n",
    "    min_data = np.min(data)\n",
    "    data = (data-min_data)/(max_data-min_data+1e-6)\n",
    "    return data-0.5\n",
    "\n",
    "def load_audio_file(file_path, input_length=4096):\n",
    "    \n",
    "    if file_path not in Loaded_data:\n",
    "        data = librosa.core.load(file_path, sr=None) \n",
    "        data = librosa.core.resample(data[0], data[1], 11025)\n",
    "        Loaded_data[file_path] = data\n",
    "    else:\n",
    "        data = Loaded_data[file_path]\n",
    "    \n",
    "    if len(data)>input_length:\n",
    "        max_offset = len(data)-input_length\n",
    "        offset = np.random.randint(max_offset)\n",
    "        data = data[offset:input_length+offset]\n",
    "        \n",
    "    else:\n",
    "        T = np.zeros(input_length, dtype=float)\n",
    "        T[:len(data)] = data\n",
    "        data = T\n",
    "        #max_offset = input_length - len(data)\n",
    "        ##offset = np.random.randint(max_offset)\n",
    "        #data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "        \n",
    "    data = audio_norm(data)\n",
    "    return np.array([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T04:27:54.207980Z",
     "start_time": "2021-02-09T04:27:54.178990Z"
    }
   },
   "outputs": [],
   "source": [
    "class CoughDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, cough_data_path, non_cough_data_path, train=True, split = 0.8, seed=1):\n",
    "        \n",
    "        # Load Data\n",
    "        self.input_length = 4096\n",
    "        self.cough_data = pickle.load(open(cough_data_path, 'rb'))\n",
    "        self.keys = list(self.cough_data.keys())\n",
    "        self.non_cough_df = pd.read_csv(non_cough_data_path)\n",
    "        \n",
    "        # set Seed\n",
    "        random.seed(seed)\n",
    "        \n",
    "        # shuffle Data\n",
    "        random.shuffle(self.keys)\n",
    "        \n",
    "        \n",
    "        self.non_cough_data = pd.read_csv(non_cough_data_path)\n",
    "        self.non_cough_data = self.non_cough_data[self.non_cough_data.label!='Cough'][:len(self.keys)]\n",
    "        \n",
    "        \n",
    "        # split Data\n",
    "        if train:\n",
    "            self.keys = self.keys[:int(len(self.keys)*split)]\n",
    "            self.non_cough_data = self.non_cough_data[:int(len(self.keys)*split)]\n",
    "        else:\n",
    "            self.keys = self.keys[int(len(self.keys)*split):]\n",
    "            self.non_cough_data = self.non_cough_data[int(len(self.keys)*split):]\n",
    "        \n",
    "\n",
    "        self.non_cough_idx = 0\n",
    "        self.cough_idx = 0\n",
    "        self.max_len = len(self.keys)\n",
    "        # load env_sounds\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.keys)*2\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # rnadomly select positive of negetaive instannce\n",
    "        if random.choice([False, True]):\n",
    "            non_cough_file_path = 'data/freesound-audio-tagging/audio_train/' + list(self.non_cough_df[self.non_cough_idx: self.non_cough_idx+1].fname)[0]\n",
    "            self.non_cough_idx = 0 if self.non_cough_idx+1>=self.max_len else self.non_cough_idx+1\n",
    "            return load_audio_file(non_cough_file_path), 0\n",
    "        \n",
    "        else:\n",
    "            cough_data_base = np.zeros(self.input_length)\n",
    "            cough_data_instance = self.cough_data[self.keys[self.cough_idx]]\n",
    "            self.cough_idx = 0 if self.cough_idx+1>=self.max_len else self.cough_idx+1\n",
    "            \n",
    "            instance_length = len(cough_data_instance)\n",
    "            \n",
    "            if instance_length/self.input_length < 1:\n",
    "                start_idx =  int(self.input_length/2 - int(instance_length/2))\n",
    "                cough_data_base[start_idx:instance_length+start_idx] = cough_data_instance\n",
    "            \n",
    "            else:\n",
    "                start_idx = int(instance_length/2)-int(self.input_length/2)\n",
    "                cough_data_base = cough_data_instance[start_idx: start_idx+self.input_length]\n",
    "            \n",
    "            return np.array([audio_norm(cough_data_base)]), 1\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T04:28:08.869282Z",
     "start_time": "2021-02-09T04:28:07.931584Z"
    }
   },
   "outputs": [],
   "source": [
    "Cough_Train_Data = CoughDataset('data/collected/data/collected_data_11025.pkl', 'data/freesound-audio-tagging/train.csv')\n",
    "Cough_Test_Data = CoughDataset('data/collected/data/collected_data_11025.pkl', 'data/freesound-audio-tagging/train.csv', train = False)\n",
    "\n",
    "mini_batch_size = 64\n",
    "Cough_Train_Dataloader = DataLoader(Cough_Train_Data, batch_size=mini_batch_size, shuffle=True)\n",
    "Cough_Test_Dataloader = DataLoader(Cough_Test_Data, batch_size=mini_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T04:28:53.667927Z",
     "start_time": "2021-02-09T04:28:49.373303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 16, 4090]             160\n",
      "              ReLU-2             [-1, 16, 4090]               0\n",
      "            Conv1d-3             [-1, 16, 4084]           2,320\n",
      "              ReLU-4             [-1, 16, 4084]               0\n",
      "         MaxPool1d-5              [-1, 16, 255]               0\n",
      "           Dropout-6              [-1, 16, 255]               0\n",
      "            Conv1d-7              [-1, 32, 255]           1,568\n",
      "              ReLU-8              [-1, 32, 255]               0\n",
      "            Conv1d-9              [-1, 32, 255]           3,104\n",
      "             ReLU-10              [-1, 32, 255]               0\n",
      "        MaxPool1d-11               [-1, 32, 63]               0\n",
      "          Dropout-12               [-1, 32, 63]               0\n",
      "           Conv1d-13               [-1, 32, 63]           3,104\n",
      "             ReLU-14               [-1, 32, 63]               0\n",
      "           Conv1d-15               [-1, 32, 63]           3,104\n",
      "             ReLU-16               [-1, 32, 63]               0\n",
      "        MaxPool1d-17               [-1, 32, 15]               0\n",
      "          Dropout-18               [-1, 32, 15]               0\n",
      "           Conv1d-19               [-1, 96, 15]           9,312\n",
      "             ReLU-20               [-1, 96, 15]               0\n",
      "           Conv1d-21               [-1, 96, 15]          27,744\n",
      "             ReLU-22               [-1, 96, 15]               0\n",
      "        MaxPool1d-23                [-1, 96, 3]               0\n",
      "           Linear-24                   [-1, 64]           6,208\n",
      "             ReLU-25                   [-1, 64]               0\n",
      "           Linear-26                  [-1, 512]          33,280\n",
      "             ReLU-27                  [-1, 512]               0\n",
      "           Linear-28                   [-1, 42]          21,546\n",
      "          Softmax-29                   [-1, 42]               0\n",
      "================================================================\n",
      "Total params: 111,450\n",
      "Trainable params: 111,450\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 2.46\n",
      "Params size (MB): 0.43\n",
      "Estimated Total Size (MB): 2.90\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class FreeSound_Sense(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(FreeSound_Sense, self).__init__()\n",
    "        self.conv1d_1_16_9 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=9, padding=True)\n",
    "        self.conv1d_16_16_9 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=9, padding=True)\n",
    "        self.conv1d_16_32_3 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=True)\n",
    "        self.conv1d_32_32_3 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=True)\n",
    "        self.conv1d_32_96_3 = nn.Conv1d(in_channels=32, out_channels=96, kernel_size=3, padding=True)\n",
    "        self.conv1d_96_96_3 = nn.Conv1d(in_channels=96, out_channels=96, kernel_size=3, padding=True)\n",
    "        \n",
    "        self.maxpool_16 = nn.MaxPool1d(16)\n",
    "        self.maxpool_4 = nn.MaxPool1d(4)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigm = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        self.fc_96_64 = nn.Linear(in_features=96, out_features=64)\n",
    "        self.fc_64_512 = nn.Linear(in_features=64, out_features=512)\n",
    "        self.fc_512_42 = nn.Linear(in_features=512, out_features=42)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # First Block\n",
    "        x = self.conv1d_1_16_9(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv1d_16_16_9(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool_16(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Second Block\n",
    "        x = self.conv1d_16_32_3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv1d_32_32_3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool_4(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Third Block\n",
    "        x = self.conv1d_32_32_3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv1d_32_32_3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool_4(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Fourth Block\n",
    "        x = self.conv1d_32_96_3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv1d_96_96_3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool_4(x)\n",
    "        x = torch.mean(x, 2)\n",
    " \n",
    "        # Final Layers\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc_96_64(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc_64_512(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc_512_42(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "Model = FreeSound_Sense()\n",
    "Model.float()\n",
    "Model.to(device)\n",
    "summary(Model, (1, 4096))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T04:30:03.770467Z",
     "start_time": "2021-02-09T04:30:03.661500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 16, 4090]             160\n",
      "              ReLU-2             [-1, 16, 4090]               0\n",
      "            Conv1d-3             [-1, 16, 4084]           2,320\n",
      "              ReLU-4             [-1, 16, 4084]               0\n",
      "         MaxPool1d-5              [-1, 16, 255]               0\n",
      "           Dropout-6              [-1, 16, 255]               0\n",
      "            Conv1d-7              [-1, 32, 255]           1,568\n",
      "              ReLU-8              [-1, 32, 255]               0\n",
      "            Conv1d-9              [-1, 32, 255]           3,104\n",
      "             ReLU-10              [-1, 32, 255]               0\n",
      "        MaxPool1d-11               [-1, 32, 63]               0\n",
      "          Dropout-12               [-1, 32, 63]               0\n",
      "           Conv1d-13               [-1, 32, 63]           3,104\n",
      "             ReLU-14               [-1, 32, 63]               0\n",
      "           Conv1d-15               [-1, 32, 63]           3,104\n",
      "             ReLU-16               [-1, 32, 63]               0\n",
      "        MaxPool1d-17               [-1, 32, 15]               0\n",
      "          Dropout-18               [-1, 32, 15]               0\n",
      "           Conv1d-19               [-1, 96, 15]           9,312\n",
      "             ReLU-20               [-1, 96, 15]               0\n",
      "           Conv1d-21               [-1, 96, 15]          27,744\n",
      "             ReLU-22               [-1, 96, 15]               0\n",
      "        MaxPool1d-23                [-1, 96, 3]               0\n",
      "           Linear-24                   [-1, 64]           6,208\n",
      "             ReLU-25                   [-1, 64]               0\n",
      "           Linear-26                  [-1, 512]          33,280\n",
      "             ReLU-27                  [-1, 512]               0\n",
      "           Linear-28                    [-1, 2]           1,026\n",
      "          Softmax-29                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 90,930\n",
      "Trainable params: 90,930\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 2.46\n",
      "Params size (MB): 0.35\n",
      "Estimated Total Size (MB): 2.82\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "Model = FreeSound_Sense()\n",
    "# uncomment if doing transfer learning\n",
    "Model.load_state_dict(torch.load(\"model_weights/FreeSound_1D_conv_small_164_epoch.stDict\"))\n",
    "Model.fc_512_42 = nn.Linear(in_features=512, out_features=2)\n",
    "\n",
    "# Comment tnext line of doig  tarnsfer learning\n",
    "#Model.load_state_dict(torch.load(\"model_weights/Cough_Data_1D_conv_global_pool_deep_batchnorm_15_epoch_95Acc.stDict\"))\n",
    "\n",
    "\n",
    "\n",
    "Model.float()\n",
    "Model.to(device)\n",
    "\n",
    "# Change the last layer\n",
    "summary(Model, (1, 4096))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(Model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# For the first 100 epoch only train the last 3 layers of FC after that connect the below loop\n",
    "for i, param in enumerate(Model.parameters()):\n",
    "    if i not in [15, 16, 17]:\n",
    "        param.requires_grad = False     \n",
    "optimizer = optim.Adam(Model.parameters(), lr=0.0005, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T04:30:54.494210Z",
     "start_time": "2021-02-09T04:30:18.349791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ef60862e82413c93174b1eb13f8019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a014d8ef4964a438ed7390f8bfef0a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=182), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Loss:  0.5185574144124985\n",
      "Train Acc  79.0264423076923\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb9a350ddc2744e6bdb5d233e8e73f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=46), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valid Acc  78.80434782608695\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17f0f341c2345c3b70015bd898dddc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=182), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Loss:  0.49667586091455523\n",
      "Train Acc  80.73489010989012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8bd7390573412a933ad35e0527d801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=46), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valid Acc  78.94021739130434\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7db8d1952754581ab0991b3a25de6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=182), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Loss:  0.4988730702098909\n",
      "Train Acc  80.46016483516483\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e410e72845f4858bb3a79536bc81857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=46), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valid Acc  79.38179347826087\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfd053e1e0af4018acb13555351ff496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=182), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-21b5955b5c0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mdata_progress_bar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCough_Train_Dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mpositives\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_progress_bar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m                 \u001b[1;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1079\u001b[0m             \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1081\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m             \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     61\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# scalars\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "Model.to(device)\n",
    "\n",
    "epoch_progress_bar = tqdm.tqdm(range(0, 500))\n",
    "\n",
    "for epoch in epoch_progress_bar:\n",
    "    avg_epoch_loss = 0\n",
    "    data_progress_bar = tqdm.tqdm(Cough_Train_Dataloader)\n",
    "    positives=0\n",
    "    for data, targets in data_progress_bar:\n",
    "        data = data.float().to(device)\n",
    "        targets = targets.long().to(device)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = Model(data)\n",
    "        \n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_val = loss.item()\n",
    "        avg_epoch_loss+=loss_val\n",
    "        data_progress_bar.set_description(desc=\"Loss: \"+str(loss_val))\n",
    "        \n",
    "        outputs = np.argmax(outputs.detach().cpu().numpy(), axis=1)\n",
    "        targets = targets.cpu().numpy()\n",
    "        positives += np.sum(targets==outputs)\n",
    "    \n",
    "    print('Epoch Loss: ', str(avg_epoch_loss/len(Cough_Train_Dataloader)))\n",
    "    print('Train Acc ', str(positives*100/(len(Cough_Train_Dataloader)*mini_batch_size)))\n",
    "    \n",
    "    # Validation\n",
    "    data_test_progress_bar = tqdm.tqdm(Cough_Test_Dataloader)\n",
    "    positives=0\n",
    "    for data, targets in data_test_progress_bar:\n",
    "        data = data.float().to(device)\n",
    "        targets = targets.numpy()\n",
    "        outputs = Model(data)\n",
    "        outputs = np.argmax(outputs.detach().cpu().numpy(), axis=1)\n",
    "        positives += np.sum(targets==outputs)\n",
    "        \n",
    "    print('Valid Acc ', str(positives*100/(len(Cough_Test_Dataloader)*mini_batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T04:31:18.000680Z",
     "start_time": "2021-02-09T04:31:17.969687Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(Model.state_dict(), \"model_weights/Cough_Data_1D_conv_small_3_epoch_80Acc.stDict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T19:07:29.478619Z",
     "start_time": "2021-02-08T19:07:28.077072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.984375 63\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(tensor(0), 0, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(0), 1, False),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(0), 0, True),\n",
       " (tensor(1), 1, True),\n",
       " (tensor(0), 0, True)]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "for data in Cough_Train_Dataloader:\n",
    "    if i==2:\n",
    "        O = Model(data[0].float().to(device))\n",
    "        A = data[1]\n",
    "        #print(data[1])\n",
    "        break\n",
    "    i+=1\n",
    "O = O.detach().cpu().numpy()\n",
    "K = np.argmax(O, axis=1)==A.numpy()\n",
    "print(np.sum(K)/len(K), np.sum(K))\n",
    "list(zip(A, np.argmax(O, axis=1), K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
